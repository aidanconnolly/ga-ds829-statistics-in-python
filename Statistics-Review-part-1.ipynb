{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Statistics Fundamentals Part 1\n",
    "\n",
    "_Authors: Alexander Egorenkov (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "- Review basics of linear algebra in preperation for Sklearn documentaion.\n",
    "- Use NumPy and Pandas libraries to analyze datasets to extract summary statistics: mean, median, mode, max, min, quartile, inter-quartile range, variance, standard deviation, and correlation.\n",
    "- Create basic data visualizations - including: scatter plots, box plots, and histograms.\n",
    "- Use visualizations to discern characteristics and trends in a dataset.\n",
    "- Describe the bias and variance of statistical estimators.\n",
    "- Use summary statistics and data visualizations to identify a normal distribution within a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Where are we in the data science workflow?](#where-are-we-in-the-data-science-workflow)\n",
    "- [Linear Algebra Review](#linear-algebra-review)\n",
    "\t- [Scalars, vectors and matrices](#scalars-vectors-and-matrices)\n",
    "\t- [Basic matrix algebra](#basic-matrix-algebra)\n",
    "\t- [Dot product](#dot-product)\n",
    "\t- [Matrix multiplication](#matrix-multiplication)\n",
    "\t- [Vector norm](#vector-norm)\n",
    "- [Linear Algebra Applications to Machine Learning](#linear-algebra-applications-to-machine-learning)\n",
    "\t- [Distance between actual values and predicted values](#distance-between-actual-values-and-predicted-values)\n",
    "\t- [Mean Squared Error](#mean-squared-error)\n",
    "\t- [Least squares](#least-squares)\n",
    "- [Codealong: Examining the Titanic Dataset](#codealong-examining-the-titanic-dataset)\n",
    "- [Descriptive Statistics Fundamentals](#descriptive-statistics-fundamentals)\n",
    "\t- [Measures of Central Tendency](#measures-of-central-tendency)\n",
    "\t- [Math Review](#math-review)\n",
    "\t- [Measures of Dispersion: Standard Deviation and Variance](#measures-of-dispersion-standard-deviation-and-variance)\n",
    "- [Our First Model](#our-first-model)\n",
    "- [A Short Introduction to Model Bias and Variance](#a-short-introduction-to-model-bias-and-variance)\n",
    "\t- [Bias-Variance decomposition](#bias-variance-decomposition)\n",
    "\t- [Example using Bessel's correction](#example-using-bessels-correction)\n",
    "- [Correlation and Association](#correlation-and-association)\n",
    "\t- [Codealong: Correlation in Pandas](#codealong-correlation-in-pandas)\n",
    "- [The Normal Distribution](#the-normal-distribution)\n",
    "\t- [What is the Normal Distribution?](#what-is-the-normal-distribution)\n",
    "\t- [Skewness](#skewness)\n",
    "\t- [Kurtosis](#kurtosis)\n",
    "- [Determining the Distribution of Your Data](#determining-the-distribution-of-your-data)\n",
    "\t- [Exercise](#exercise)\n",
    "- [Topic Review](#topic-review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# This makes sure that graphs render in your notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"where-are-we-in-the-data-science-workflow\"></a>\n",
    "## Where are we in the data science workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Science Workflow](./assets/images/data-science-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-algebra-review\"></a>\n",
    "## Linear Algebra Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scalars-vectors-and-matrices\"></a>\n",
    "### Scalars, vectors and matrices\n",
    "\n",
    "A **scalar** is a single number.\n",
    "\n",
    "$$a$$\n",
    "\n",
    "A **vector** is several numbers in sequence.\n",
    "\n",
    "$$\\vec{u} = \\left[ \\begin{array}{c}\n",
    "1&3&7\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a vector using np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An m x n **matrix** is a rectangular array of numbers with m rows and n columns. Each number in the matrix is an entry. Entries can be denoted $a_{mn}$\n",
    "\n",
    "$$A= \\left[ \\begin{array}{c}\n",
    "a_{11} & a_{12} & ... & a_{1n}  \\\\\n",
    "a_{21} & a_{22} & ... & a_{2n}  \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{m1} & a_{m2} & ... & a_{mn}\n",
    "\\end{array} \\right]$$\n",
    "$$A \\in \\mathbb{R}^{mn}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a matrix using np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basic-matrix-algebra\"></a>\n",
    "### Basic matrix algebra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition and subtraction\n",
    "Vector **addition** is straightforward. If two vectors are of equal dimensions:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right],  \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{v} + \\vec{w} =\n",
    "\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] + \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "1+1 \\\\\n",
    "3+0 \\\\\n",
    "7+1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "8\n",
    "\\end{array} \\right]\n",
    "$\n",
    "\n",
    "(Subtraction is similar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the vectors together with +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar multiplication\n",
    "We scale a vector with **scalar multiplication**, multiplying a vector by a scalar (single quantity):\n",
    "\n",
    "$ 2 \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2*1 \\\\\n",
    "2*3 \\\\\n",
    "2*7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "6 \\\\\n",
    "14\n",
    "\\end{array} \\right]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiply v by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dot-product\"></a>\n",
    "### Dot product\n",
    "The **dot product** of two _n_-dimensional vectors is:\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} =\\sum _{i=1}^{n}v_{i}w_{i}=v_{1}w_{1}+v_{2}w_{2}+\\cdots +v_{n}w_{n} $\n",
    "\n",
    "So, if:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right], \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} = 1*1 + 3*0 + 7*1 = 8 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])\n",
    "\n",
    "# calculate the dot product of v and w using np.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"matrix-multiplication\"></a>\n",
    "### Matrix multiplication\n",
    "**Matrix multiplication**, $A_{mn} * B_{ij}$, is valid when the left matrix has the same number of columns as the right matrix has rows ($n = i$). Each entry is the dot product of corresponding row and column vectors.\n",
    "\n",
    "![](./assets/images/matrix-multiply-a.gif)\n",
    "(Image: mathisfun.com!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,  64],\n",
       "       [139, 154]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vector-norm\"></a>\n",
    "### Vector norm\n",
    "The **magnitude** of a vector $\\vec{v} \\in \\mathbb{R}^{n}$ in is interpretable as its length in n-dimensional space, and is calculable via the Euclidean distance:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "v_{1} \\\\\n",
    "v_{2} \\\\\n",
    "\\vdots \\\\\n",
    "v_{n}\n",
    "\\end{array} \\right]$\n",
    "\n",
    "then $\\| \\vec{v} \\| = \\sqrt{v_{1}^{2} + v_{2}^{2} + ... + v_{n}^{2}} = \\sqrt{v^Tv}$\n",
    "\n",
    "E.g. if $\\vec{v} = \n",
    "\\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{array} \\right]$, then $\\| \\vec{v} \\| = \\sqrt{3^{2} + 4^{2}} = 5$\n",
    "\n",
    "This is also called the vector **norm**. You will see this often in machine learning as least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([3,4])\n",
    "\n",
    "# calculate the norm of the vector x with np.linalg.norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-algebra-applications-to-machine-learning\"></a>\n",
    "## Linear Algebra Applications to Machine Learning\n",
    "---\n",
    "\n",
    "<a id=\"distance-between-actual-values-and-predicted-values\"></a>\n",
    "### Distance between actual values and predicted values\n",
    "We often need to know the difference between predicted values and actual values.\n",
    "We calculate this as:\n",
    "$$\\| \\vec{actual} - \\vec{predicted} \\| =\\sqrt{(actual_1 - predicted_1)^2 + (actual_2 - predict_2)^2}$$\n",
    "<a id=\"mean-squared-error\"></a>\n",
    "### Mean Squared Error\n",
    "Most of the time it's easier to read the average distance between predicted values and actual values.\n",
    "$$\\frac{1} {n} \\| \\vec{y} - f(X) \\|$$\n",
    "<a id=\"least-squares\"></a>\n",
    "### Least squares\n",
    "Many machine learning models are composed in the following form:\n",
    "$$\\min \\| \\vec{y} - f(X) \\|$$\n",
    "The goal is to minimize the distance between model predictions and actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in sklearn http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"codealong-examining-the-titanic-dataset\"></a>\n",
    "## Codealong: Examining the Titanic Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: Read in the Titanic data and look at a few summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you don't have git use this link: http://bit.ly/2ae8zAT\n",
    "titanic = pd.read_csv('http://bit.ly/2ae8zAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'survived', u'pclass', u'name', u'sex', u'age', u'sibsp', u'parch',\n",
       "       u'ticket', u'fare', u'cabin', u'embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the dimensions of the DataFrame using the `.shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preview data dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the data types of the columns using the `.dtypes` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What are the column data types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 5 rows of the data using the `.head()` built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `.value_counts()` built-in function to count the values of each type in the `pclass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the values of the the plcass variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull up descriptive statistics for each variables using the built-in `.describe()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull up descriptive statistics for each variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosing data problems\n",
    "\n",
    "- Whenever you get a new dataset, the fastest way to find mistakes and inconsistencies is to look at the descriptive statistics\n",
    "  - If anything look too high or too low relative to your experience, there may be issues with the data collection\n",
    "- Your data may have a lot of missing values and may need to be cleaned meticulously before being combined with other data\n",
    "  - You can take a quick average or moving average to smooth out the data and combine that to preview your results before you embark on your much longer data cleaning journey\n",
    "  - Sometimes filling in missing values with their means or medians will be the best solution for dealing with missing data other times you may want to drop the offending rows or do real imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"descriptive-statistics-fundamentals\"></a>\n",
    "## Descriptive Statistics Fundamentals\n",
    "---\n",
    "\n",
    "#### Objective: Review the following terms: mean, median, mode, interquartile-range, variance, and standard deviation and then view and example of how this information can be produced using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A QUICK REVIEW OF NOTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of a constant, k,  n times\n",
    "$$\\sum_{i=1}^nk$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k + k + k + k + ... + k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all numbers from 1 up to n:\n",
    "$$\\sum_{i=1}^ni$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 + 2 + 3 + ... + n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all x from the first x entry to the nth x entry:\n",
    "$$\\sum_{i=0}^nx_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_1 + x_2 + x_3 + ... + x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codealong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the sum of 7 4s using base Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the sum of 7 4s using NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the sum of 1 through 10 using base Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the titanic.fare column compute the total fare paid by passengers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"measures-of-central-tendency\"></a>\n",
    "### Measures of Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean\n",
    "- median\n",
    "- mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEAN\n",
    "The mean, also known as an average or the expected value is defined as:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEDIAN\n",
    "The median refers to the midpoint in a series of numbers.\n",
    "\n",
    "$$ 0,1,2,[3],5,5,9 $$\n",
    "\n",
    "$$ 1,3,4,[4,5],5,5,7 $$\n",
    "\n",
    "To find the median:\n",
    "- Arrange the numbers in order smallest to \n",
    "  largest.\n",
    "\n",
    "- If there is an odd number of values, the \n",
    "  middle value is the median.\n",
    "\n",
    "- If there is an even number of values, the \n",
    "  average of the middle two values is the \n",
    "  median.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODE\n",
    "The mode of a set of values is the value that occurs most often.\n",
    "A set of values may have more than one mode or no mode.\n",
    "\n",
    "$$1,0,1,5,7,8,9,3,4,1$$ 1 is the mode since it occurs the most often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codealong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using base Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What was the median fare paid (using Pandas)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Pandas to find the most common fare paid on the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"math-review\"></a>\n",
    "### Math Review\n",
    "\n",
    "**How do we measure distance?**\n",
    "\n",
    "One method is two take the difference between two points\n",
    "$$X_2 - X_1$$\n",
    "\n",
    "However, this can be inconvenient due to negative numbers.\n",
    "\n",
    "We often use this square root trick to deal with negative numbers\n",
    "$$\\sqrt{(X_2-X_1)^2}$$\n",
    "\n",
    "**What about distance in multiple dimensions?**\n",
    "\n",
    "We can turn to the Pythagorean theorem\n",
    "$$a^2 + b^2 = c^2$$\n",
    "\n",
    "To find the distance along a diagnal it is sufficient to measure one dimension at a time\n",
    "$$\\sqrt{a^2 + b^2} = c$$\n",
    "\n",
    "More generally we can write this as (You'll see this in machine learning papers)\n",
    "$$\\|X\\|_2 = \\sqrt{\\sum{x_i^2}} = c$$\n",
    "\n",
    "If we want to work with points rather than distances, we can write\n",
    "$$\\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} = c$$\n",
    "or\n",
    "$$\\sqrt{\\sum{(x_i - y_i)^2}} = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"measures-of-dispersion-standard-deviation-and-variance\"></a>\n",
    "### Measures of Dispersion: Standard Deviation and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation (SD, σ for population standard deviation, s for sample standard deviation) is a measure that is used to quantify the amount of variation or dispersion from the mean of a set of data values. A low standard deviation means that most of the numbers are very close to the average. A high standard deviation means that the numbers are spread out.\n",
    "\n",
    "Standard deviation is the square root of variance.\n",
    "$$variance = \\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "$$s = \\sqrt{\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can be a lot to take in so let's break it down in Python.\n",
    "\n",
    "#### Assign the first 5 rows of titanic age data to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the first 5 rows of titanic age data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the variance by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate variance by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the variance and the standard deviation using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verify with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"our-first-model\"></a>\n",
    "## Our First Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our first model from scratch. We'll predict the fare column in the titanic data. What data will we use? Actually, none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest model we can build is an estimation of the mean, median, or most common value. If we have no feature matrix and only an outcome, this is the best approach to make a prediction using only empirical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems silly, but we'll actually use it all the time to create a baseline of how well we do with no data, and whether our more sophisticated models make an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the fare column from the titanic data and store it in variable y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Fare column from the titanic data and store as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create predictions y_pred (in this case just the mean of y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stored predictions in y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the least squares (euclidean distance) formula to see how close our predictions are on average:\n",
    "\n",
    "This is also known as mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Squared Error is really hard to read, Let's look at Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the root mean square error, which is the square root of the mean squared distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"a-short-introduction-to-model-bias-and-variance\"></a>\n",
    "## A Short Introduction to Model Bias and Variance \n",
    "\n",
    "---\n",
    "\n",
    "(There will be more intros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, **Bias** shows how on target a model is in its predictions.\n",
    "\n",
    "**Variance** shows how reliable a model is in its performance.\n",
    "\n",
    "These characteristics have important interactions, but we will save that for later.\n",
    "\n",
    "![Bias and Variance](./assets/images/biasVsVarianceImage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we just calculated Mean Squared Error to see how good our prediction was? It turns out we can do this for any statistical estimator, including means, variances, and machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even decompose Mean Squared Error to identify where the source of error comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bias-variance-decomposition\"></a>\n",
    "### Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notation $f$ refers to a perfect model while $\\hat{f}$ refers to our model.\n",
    "\n",
    "**Bias**\n",
    "\n",
    "Error due to bias is calculated at the difference between the expected prediction of our model and the correct value we are trying to predict.\n",
    "$$Bias = E[\\hat{f}(x)] - f(x)$$\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Error due to variance is taken as the variability of a model prediction for a given point.\n",
    "\n",
    "$$Variance = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$$\n",
    "\n",
    "**Mean Squared Error**\n",
    "$$MSE(\\hat{f}(x)) = Var(\\hat{f}(x)) + Bias(\\hat{f}(x),f(x))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic will come up again, it's enough for now to know that we can decompose MSE into Bias of the estimator and Variance of the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"example-using-bessels-correction\"></a>\n",
    "### Example using Bessel's correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rarely practical to measure every single item in a population to gather a statistic. We will usually sample a few items and use those to infer a population value.\n",
    "\n",
    "For example, we can take a class of 200 students and measure their height, but rather than measuring everyone, we select students at random to estimate the average height in the class and the variance of the height in the class.\n",
    "\n",
    "We know we can take the mean as follows:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$\n",
    "\n",
    "What about the variance?\n",
    "\n",
    "Intuitively and by definition, population variance looks like this (the average distance from the mean):\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n}$$\n",
    "\n",
    "It's actually better to use the following for a sample (why?):\n",
    "\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "In some cases, we may even use:\n",
    "\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n+1}$$\n",
    "\n",
    "Detailed explanations can be found here:\n",
    "- https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "- https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heights = np.random.rand(200) + 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_means(sample_size):\n",
    "    true_mean = np.mean(heights)\n",
    "    mean_heights = []\n",
    "    for n in range(5,sample_size):\n",
    "        for j in range(30):\n",
    "            mean_height = np.mean(np.random.choice(heights, n, replace=False))\n",
    "            mean_heights.append((n, mean_height))\n",
    "    sample_height = pd.DataFrame(mean_heights, columns=['sample_size', 'height'])\n",
    "    sample_height.plot.scatter(x='sample_size', y='height', figsize=(14, 4), alpha=0.5)\n",
    "    plt.axhline(y=true_mean, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Mean Estimator\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_variances(sample_size):\n",
    "    true_variance = np.var(heights)\n",
    "    var_heights = []\n",
    "    for n in range(5,sample_size):\n",
    "        for j in range(30):\n",
    "            var_height1 = np.var(np.random.choice(heights, n, replace=False), ddof=0)\n",
    "            var_height2 = np.var(np.random.choice(heights, n, replace=False), ddof=1)\n",
    "            var_height3 = np.var(np.random.choice(heights, n, replace=False), ddof=-1)\n",
    "            var_heights.append((n, var_height1, var_height2, var_height3))\n",
    "    sample_var = pd.DataFrame(var_heights, columns=['sample_size', 'variance1', 'variance2', 'variance3'])\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance1', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Population Variance Estimator (n)\")\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance3', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Biased Sample Variance Estimator (n+1)\")\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance2', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Sample Variance Estimator (n-1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a5d4988cb04723a6ee1b16b806fb42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_means, sample_size=(5,200));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The red line above is the true average height, but because we don't want to ask 200 people about their height, we take a samples.\n",
    "\n",
    "- The blue dots show the estimate of the average height after taking a sample. To give us an idea of how sampling works, we simulate taking multiple sample.\n",
    "\n",
    "- The X axis shows the sample size we take, the blue dots show the likely average heights we'll conclude for a given sample size.\n",
    "\n",
    "- Even though the true average height is around 7 feet, a small sample may lead us to think that it's actually 6.7 or 7.3 feet. \n",
    "\n",
    "- Notice that the red line is in the center of our estimates. On average, we are correct and have no bias.\n",
    "\n",
    "- If we take a larger sample size we get a better estimate. Meaning that the variance of our estimate gets smaller with larger samples sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b94bccfb3443babf7e9ec534de9611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_variances, sample_size=(5,200));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not all estimators are created equal.\n",
    "\n",
    "- The red line shows the true variance of height\n",
    "\n",
    "- The top graph is the Population Variance estimator, while the bottom graph is the Sample Variance estimator.\n",
    "\n",
    "- This is very subtle, but notice that the Population Variance estimator is not centered on the red line. It's actually biased and consistently underestimates the true variance, especially at low sample sizes.\n",
    "\n",
    "- You may also notice that the scatter of of Population Variance estimator is smaller. That means the variance of the Population Variance estimator is smaller. That phrase can be really confusing, it's the variability of the estimator. \n",
    "\n",
    "- Play around with the sliders to get a good view of the graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"correlation-and-association\"></a>\n",
    "## Correlation and Association\n",
    "---\n",
    "\n",
    "Correlation measures how variables related to each other.\n",
    "\n",
    "Typical when we talk about the pearson correlation coefficient which is a measure of **linear** association\n",
    "\n",
    "We refer to perfect correlation as colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example correlation values](./assets/images/correlation_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"codealong-correlation-in-pandas\"></a>\n",
    "### Codealong: Correlation in Pandas\n",
    "\n",
    "**Objective: Explore options for measuring and visualizing correlation in Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the correlation matrix for all titanic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use seaborn to plot a heatmap of the correlation matrix.\n",
    "\n",
    "The `sns.heatmap()` function will do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use seaborn to plot a correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a closer look at survived and fare using a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-normal-distribution\"></a>\n",
    "## The Normal Distribution\n",
    "---\n",
    "\n",
    "**Objective: Introduce normal (gaussian distributions) and how to identify them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Math Review\n",
    "- What is an event space?\n",
    "  - A listing of all possible occurances\n",
    "- What is a probability distribution?\n",
    "  - A function that describes how events occur in an event space\n",
    "- What are general properties of probability distributions?\n",
    "  - All probabilities of an event are between 0 and 1\n",
    "  - The probability that something occurs is almost certain or 1.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-the-normal-distribution\"></a>\n",
    "### What is the Normal Distribution?\n",
    "- A normal distribution is often a key assumption to many models.\n",
    "  - In practice, if the normal distribution assumption is not met, it's not the end of the world. Your model is just less efficient in most cases.\n",
    "\n",
    "- The normal distribution depends upon the mean and the standard deviation.\n",
    "\n",
    "- The mean determines the center of the distribution.  The standard deviation determines the height and width of the distribution.\n",
    "\n",
    "- Normal distributions are symmetric, bell-shaped curves.\n",
    "\n",
    "- When the standard deviation is large, the curve is short and wide.\n",
    "\n",
    "- When the standard deviation is small, the curve it tall and narrow.\n",
    "\n",
    "![normal distribution](../assets/images/normal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we care about Normal distributions?\n",
    "- Shows up in nature very often\n",
    "- Aggregated processes tend to distribute normally regardless of their underlying distribution provided that the processes are uncorrelated or weakly correlated (Central Limit Theorem)\n",
    "- Good simplification that makes it easy to make approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a histogram of 1000 samples from a random normal distribution.\n",
    "\n",
    "The `np.random.randn()` function will draw from a random normal distribution with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of several random normal samples from numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"skewness\"></a>\n",
    "###  Skewness\n",
    "- Skewness is a measure of the asymmetry of the distribution of a random variable about its mean.\n",
    "- Skewness can be positive or negative, or even undefined.\n",
    "- Notice that the mean, median, and mode are the same when there is no skew\n",
    "![skewness](./assets/images/skewness---mean-median-mode.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a lognormal distribution generated with numpy.\n",
    "\n",
    "Take 1000 samples using `np.random.lognormal` and plot them on a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a lognormal distribution generated with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Real World Application - When mindfullness beats complexity\n",
    "- Skewness is surprisingly important.\n",
    "- Most algorithms implicitly use the mean by default when making approximations.\n",
    "- If you know your data is heavily skewed you may have to either transform your data or set your algorithms to work with the median.\n",
    "- In the DIDI tech challenge, changing a few default options quickly put you in the 80th percentile, ahead of some very brilliant programmers who missed the basics. This amount to switch the algorithm from estimating a mean to estimating a median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kurtosis\"></a>\n",
    "### Kurtosis\n",
    "- Kurtosis is a measure of whether the data are peaked or flat relative to a normal distribution.\n",
    "- Datasets with high kurtosis tend to have a distinct peak near the mean, decline rather rapidly, and have heavy tails. \n",
    "\n",
    "![kurtosis](./assets/images/kurtosis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Real World Application - Risk Analysis\n",
    "- Long-tailed distributions with high kurtosis elude intuition, we naturally think the event is too improbable to pay attention to\n",
    "- It's often the case that there is a a large cost associated with the very low probability event as is the case with hurricane damage\n",
    "- It's unlikely you will get hit by a category 5 hurricane, but when you do, the damage is catastrophic\n",
    "- Pay attention to what happens at the tails and whether it influences the problem at hand\n",
    "- In these cases understanding the costs may be more important than understanding the risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"determining-the-distribution-of-your-data\"></a>\n",
    "## Determining the Distribution of Your Data\n",
    "---\n",
    "\n",
    "**Objective: Introduce histograms and density plots in Pandas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/distributions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `.hist()` function of your titantic DataFrame to plot histograms of all the variables in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot all variables in titanic using histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `.plot.box()` built-in function of your titanic DataFrame to plot boxplots of your variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting all histograms can be unweildly, boxplots can be more concise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise\"></a>\n",
    "### Exercise\n",
    "\n",
    "1. Look at the titanic data variables\n",
    "- Are any of them normal?\n",
    "- Are any skewed?\n",
    "- How might this affect our modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/visualization_flow_chart.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic-review\"></a>\n",
    "## Topic Review\n",
    "---\n",
    "\n",
    "- We covered several different types of summary statistics, what are they?\n",
    "- We covered three different types of visualizations, which ones?\n",
    "- Describe bias and variance and why they are important.\n",
    "- What are some important characteristics of distributions?\n",
    "\n",
    "**Any further questions?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
